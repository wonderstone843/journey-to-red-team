# ğŸ—ï¸ Module 3 Notes: Securing the ML Pipeline

## ğŸ” What I Learned

- **The Pipeline Matters:** Attacks can hit during training, deployment, or when models are updated.
- **Provenance Tracking:** Know where every piece of data came from â€” it helps catch poisoning early.
- **Model Drift:** Over time, a model can slowly change how it behaves unless actively monitored.
- **Output Filtering:** Prevent the model from saying things it shouldnâ€™t, even under pressure.

## ğŸ§  Reflections

- Securing an AI model is like securing a factory â€” every stage of input and output must be checked.
- Red teaming a pipeline means watching for changes, leaks, and vulnerabilities that sneak in after launch.
- Even when the model is â€œdone,â€ the risk isnâ€™t.

## ğŸš€ Takeaway

> â€œDefense isnâ€™t one step â€” itâ€™s a cycle.â€

This module helped me see the big picture of **system-level security.** From the moment data enters to the moment predictions are made â€” every phase matters.
`
