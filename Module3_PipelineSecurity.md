# 🏗️ Module 3 Notes: Securing the ML Pipeline

## 🔍 What I Learned

- **The Pipeline Matters:** Attacks can hit during training, deployment, or when models are updated.
- **Provenance Tracking:** Know where every piece of data came from — it helps catch poisoning early.
- **Model Drift:** Over time, a model can slowly change how it behaves unless actively monitored.
- **Output Filtering:** Prevent the model from saying things it shouldn’t, even under pressure.

## 🧠 Reflections

- Securing an AI model is like securing a factory — every stage of input and output must be checked.
- Red teaming a pipeline means watching for changes, leaks, and vulnerabilities that sneak in after launch.
- Even when the model is “done,” the risk isn’t.

## 🚀 Takeaway

> “Defense isn’t one step — it’s a cycle.”

This module helped me see the big picture of **system-level security.** From the moment data enters to the moment predictions are made — every phase matters.
`
